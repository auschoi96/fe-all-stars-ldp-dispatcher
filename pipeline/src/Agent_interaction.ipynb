{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edc3af1a-c9ed-44af-bd42-2e595de6ab02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import uuid\n",
    "import mlflow\n",
    "import dspy\n",
    "\n",
    "mlflow.dspy.autolog()\n",
    "gpt_oss = dspy.LM(model=\"databricks/databricks-gpt-oss-120b\", cache=False)\n",
    "dspy.configure(lm=gpt_oss)\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Access Databricks Asset Bundle variables passed via base_parameters\n",
    "try:\n",
    "    # These variables are passed from the DAB job configuration\n",
    "    instance_name = dbutils.widgets.get(\"instance_name\")\n",
    "    current_username = dbutils.widgets.get(\"current_username\")\n",
    "    current_shortName = dbutils.widgets.get(\"current_shortname\")\n",
    "    batch_interval = dbutils.widgets.get(\"batch_interval\")\n",
    "except:\n",
    "    # Fallback values for development/testing\n",
    "    instance_name = \"fe_shared_demo\"\n",
    "    current_username = \"default_user\"\n",
    "    batch_interval = \"180\"\n",
    "\n",
    "print(f\"Using instance_name: {instance_name}\")\n",
    "print(f\"Using current_username: {current_username}\")\n",
    "print(f\"Using batch_interval: {batch_interval}\")\n",
    "\n",
    "instance = w.database.get_database_instance(name=instance_name)\n",
    "cred = w.database.generate_database_credential(request_id=str(uuid.uuid4()), instance_names=[instance_name])\n",
    "\n",
    "class turbine_details_to_report(dspy.Signature):\n",
    "  \"\"\"Convert the turbine look up results to the example report below. Replace the numbers with what you see in the turbine lookup results: \n",
    "  <Example Report>\n",
    "  'Turbine Health Report - TURBINE_00000\n",
    "Time: Sep 23, 2025 07:17 UTC | Status: ðŸ”´ CRITICAL - IMMEDIATE ACTION\n",
    "Alert Summary\n",
    "THERMAL FAULT - Priority 5/5 | Dispatch Score: 100/100 | SLA: BREACH\n",
    "Current Metrics\n",
    "\n",
    "Health Score: 46/100 (min: 45) | Degradation Risk: 46.3/100\n",
    "Uptime: 0% | Status: STOPPED (5/9 readings)\n",
    "Power Output: 5.8 kW avg (52.1 kW total) | Efficiency: 6.3%\n",
    "Wind Speed: 2.0 m/s | Rotor RPM: 0.01\n",
    "\n",
    "Technical Data\n",
    "\n",
    "Temp Differential: 14Â°C | Gearbox Temp Variance: 2.6\n",
    "Vibration: 0.63 max (variance: 0.11)\n",
    "Oil Pressure: 41.0 bar (minimum)\n",
    "Maintenance Alerts: 9 over 2.4 minutes\n",
    "\n",
    "Action Required\n",
    "IMMEDIATE_INTERVENTION - Maintenance window: 1 day\n",
    "Location: 32.0Â°N, 101.5Â°W\n",
    "Issue: Unit non-generating with thermal fault. Investigate gearbox and thermal systems immediately.'\n",
    "</Example Report>\"\"\"\n",
    "\n",
    "  turbine_lookup_results: str = dspy.InputField()\n",
    "  report: str = dspy.OutputField()\n",
    "\n",
    "def agent_status_update(query):\n",
    "  \"\"\"This is used to update what the agent decided to do for each turbine. Queries must be in postgres syntax\"\"\"\n",
    "  with psycopg2.connect(\n",
    "      host=instance.read_write_dns,\n",
    "      dbname=\"databricks_postgres\",\n",
    "      user=f\"{current_username}\",\n",
    "      password=cred.token,\n",
    "      sslmode=\"require\"\n",
    "  ) as conn:\n",
    "      with conn.cursor() as cur:\n",
    "          result = cur.execute(query)\n",
    "  return result\n",
    "\n",
    "\n",
    "def turbine_lookup(turbine):\n",
    "      \"\"\"This is a query to look up information about a turbine.\"\"\"\n",
    "\n",
    "      genie_space_id = \"01f09a993be215439f76eaa8c029d6cd\"\n",
    "\n",
    "      # Start a conversation\n",
    "      conversation = w.genie.start_conversation_and_wait(\n",
    "          space_id=genie_space_id,\n",
    "          content=f\"Provide the latest detailed status and sensor readings for turbine {turbine}\",\n",
    "          timeout=datetime.timedelta(minutes=20)\n",
    "      )\n",
    "\n",
    "      result = w.genie.get_message_attachment_query_result(\n",
    "        space_id=genie_space_id,\n",
    "        conversation_id=conversation.conversation_id,\n",
    "        message_id=conversation.message_id,\n",
    "        attachment_id=conversation.attachments[0].attachment_id\n",
    "      )\n",
    "\n",
    "      # Get column names\n",
    "      column_names = [col.name for col in result.statement_response.manifest.schema.columns]\n",
    "\n",
    "      # Get data\n",
    "      data_array = result.statement_response.result.data_array\n",
    "\n",
    "      # Create DataFrame\n",
    "      df = pd.DataFrame(data_array, columns=column_names)\n",
    "      df = df.to_string()\n",
    "\n",
    "      # df = spark.table(\"users.austin_choi.gold_maintenance_alerts\")\n",
    "      # display(df)\n",
    "      # df = df.filter(df.turbine_id == turbine).orderBy(df.window_start.desc()).limit(1)\n",
    "      # display(df)     \n",
    "      # df = df.toPandas().to_string()\n",
    "      # print(df)\n",
    "      with dspy.context(lm=dspy.LM('databricks/databricks-gpt-oss-20b')):\n",
    "        predictor = dspy.Predict(turbine_details_to_report)\n",
    "        result = predictor(turbine_lookup_results=df)\n",
    "      return result.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb49f35d-6890-4693-8945-34cb84a7fdf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Make Table\n",
    "make_table = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS turbine_monitoring (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                turbine_id VARCHAR(50) NOT NULL,\n",
    "                turbine_details_and_status TEXT,\n",
    "                dispatch_priority_score DECIMAL(5,2),\n",
    "                recommended_action TEXT,\n",
    "                maintenance_alerts_count INTEGER DEFAULT 0,\n",
    "                agent_summary TEXT,\n",
    "                last_agent_action_taken TEXT,\n",
    "                Ticket_ID VARCHAR(50),\n",
    "                ticket_filed BOOLEAN DEFAULT FALSE,\n",
    "                ticket_status VARCHAR(50),\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\"\n",
    "\n",
    "agent_status_update(make_table)\n",
    "\n",
    "make_ticket_table = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS ticket_mock_table (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                Ticket_ID VARCHAR(50) NOT NULL,\n",
    "                turbine_id VARCHAR(50) NOT NULL,\n",
    "                ticket_status_output Text,\n",
    "                Ticket_Submission Text,\n",
    "                Ticket_Status Text,\n",
    "                Last_Update TIMESTAMP,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\"\n",
    "agent_status_update(make_ticket_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2725466-09c1-41aa-a2ef-d01fdd5840a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Decide which turbines need a dispatcher\n",
    "1. Get latest maintenance request\n",
    "2. Check status on lakebase \n",
    "3. determine dispatcher need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9bd83f0-3875-472c-b926-6c68496c6a2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM users.{current_shortName}.maintenance_dispatch_queue t\n",
    "WHERE maintenance_alerts_count >= 5\n",
    "QUALIFY ROW_NUMBER() OVER (\n",
    "  PARTITION BY turbine_id\n",
    "  ORDER BY alert_generated_timestamp DESC\n",
    ") <= 1\n",
    "\"\"\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144c8a25-b78c-4ebf-bbfe-3a60d3fbbe9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#add a check here to see if a ticket is already open for a turbine. If it is, skip it. \n",
    "query = \"\"\"SELECT t1.turbine_id, t1.ticket_status\n",
    "FROM turbine_monitoring t1\n",
    "INNER JOIN (\n",
    "    SELECT turbine_id, MAX(updated_at) AS max_updated_at\n",
    "    FROM turbine_monitoring\n",
    "    GROUP BY turbine_id\n",
    ") t2 ON t1.turbine_id = t2.turbine_id AND t1.updated_at = t2.max_updated_at\n",
    "where ticket_status = 'Open';\"\"\"\n",
    "\n",
    "with psycopg2.connect(\n",
    "      host=instance.read_write_dns,\n",
    "      dbname=\"databricks_postgres\",\n",
    "      user=f\"{current_username}\",\n",
    "      password=cred.token,\n",
    "      sslmode=\"require\"\n",
    "  ) as conn:\n",
    "      with conn.cursor() as cur:\n",
    "          cur.execute(query)\n",
    "          result = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed0e11e0-52e3-486e-9c71-928786bdbc30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>turbine_id</th><th>turbine_lat</th><th>turbine_lon</th><th>window_start</th><th>dispatch_priority_score</th><th>recommended_action</th><th>fault_category</th><th>estimated_maintenance_window_days</th><th>work_complexity_hours</th><th>crew_size_required</th><th>equipment_required</th><th>avg_health_score</th><th>degradation_risk_score</th><th>maintenance_alerts_count</th><th>alert_generated_timestamp</th></tr></thead><tbody><tr><td>TURBINE_00000</td><td>32.0</td><td>-101.5</td><td>2025-09-26T10:33:03.635Z</td><td>100.0</td><td>IMMEDIATE_INTERVENTION</td><td>THERMAL</td><td>1</td><td>4</td><td>3</td><td>THERMAL_IMAGING,COOLING_SYSTEM</td><td>46.111111111111114</td><td>61.55555555555556</td><td>9</td><td>2025-09-26T19:57:37.462Z</td></tr><tr><td>TURBINE_00001</td><td>32.0</td><td>-101.5</td><td>2025-09-26T10:33:03.635Z</td><td>80.0</td><td>SCHEDULED_MAINTENANCE</td><td>ELECTRICAL</td><td>7</td><td>6</td><td>1</td><td>MULTIMETER,INSULATION_TESTER</td><td>86.66666666666667</td><td>30.333333333333332</td><td>9</td><td>2025-09-26T19:57:37.462Z</td></tr><tr><td>TURBINE_00005</td><td>32.0</td><td>-101.5</td><td>2025-09-26T10:33:03.635Z</td><td>100.0</td><td>IMMEDIATE_INTERVENTION</td><td>THERMAL</td><td>1</td><td>4</td><td>3</td><td>THERMAL_IMAGING,COOLING_SYSTEM</td><td>45.55555555555556</td><td>46.77777777777778</td><td>9</td><td>2025-09-26T19:57:37.462Z</td></tr><tr><td>TURBINE_00007</td><td>32.0</td><td>-101.5</td><td>2025-09-26T10:27:08.334Z</td><td>100.0</td><td>IMMEDIATE_INTERVENTION</td><td>THERMAL</td><td>1</td><td>4</td><td>3</td><td>THERMAL_IMAGING,COOLING_SYSTEM</td><td>45.55555555555556</td><td>46.77777777777778</td><td>9</td><td>2025-09-26T19:57:37.462Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "TURBINE_00000",
         32,
         -101.5,
         "2025-09-26T10:33:03.635Z",
         100,
         "IMMEDIATE_INTERVENTION",
         "THERMAL",
         1,
         4,
         3,
         "THERMAL_IMAGING,COOLING_SYSTEM",
         46.111111111111114,
         61.55555555555556,
         9,
         "2025-09-26T19:57:37.462Z"
        ],
        [
         "TURBINE_00001",
         32,
         -101.5,
         "2025-09-26T10:33:03.635Z",
         80,
         "SCHEDULED_MAINTENANCE",
         "ELECTRICAL",
         7,
         6,
         1,
         "MULTIMETER,INSULATION_TESTER",
         86.66666666666667,
         30.333333333333332,
         9,
         "2025-09-26T19:57:37.462Z"
        ],
        [
         "TURBINE_00005",
         32,
         -101.5,
         "2025-09-26T10:33:03.635Z",
         100,
         "IMMEDIATE_INTERVENTION",
         "THERMAL",
         1,
         4,
         3,
         "THERMAL_IMAGING,COOLING_SYSTEM",
         45.55555555555556,
         46.77777777777778,
         9,
         "2025-09-26T19:57:37.462Z"
        ],
        [
         "TURBINE_00007",
         32,
         -101.5,
         "2025-09-26T10:27:08.334Z",
         100,
         "IMMEDIATE_INTERVENTION",
         "THERMAL",
         1,
         4,
         3,
         "THERMAL_IMAGING,COOLING_SYSTEM",
         45.55555555555556,
         46.77777777777778,
         9,
         "2025-09-26T19:57:37.462Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "turbine_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "turbine_lat",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "turbine_lon",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "window_start",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "dispatch_priority_score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recommended_action",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "fault_category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "estimated_maintenance_window_days",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "work_complexity_hours",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "crew_size_required",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "equipment_required",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "avg_health_score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "degradation_risk_score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "maintenance_alerts_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "alert_generated_timestamp",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     }
    }
   ],
   "source": [
    "turbines_with_open_tickets = [ticket[0] for ticket in result]\n",
    "\n",
    "# Filter dataframe to exclude turbines with open tickets\n",
    "filtered_df = df[~df['turbine_id'].isin(turbines_with_open_tickets)]\n",
    "display(filtered_df)\n",
    "query_results = filtered_df.toPandas().to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62a3f014-f2ea-4f74-8299-0528f0bf1d68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class query_dispatch_decider(dspy.Signature):\n",
    "  \"\"\"determine which turbines require filing a ticket for a dispatcher. Turbines need a dispatcher if there are more than 5 maintenance alerts. Update the status with what you decided to do. You cannot submit tickets, only change ticket_status to 'Need to File'\n",
    "  \n",
    "  Update the VALUES section of the postgres sql query below with the information you see in the query:\n",
    "  <Example Query>\n",
    "    INSERT INTO turbine_monitoring \n",
    "    (turbine_id, turbine_details_and_status, dispatch_priority_score, recommended_action, \n",
    "     maintenance_alerts_count, agent_summary, last_agent_action_taken, Ticket_ID, ticket_filed, ticket_status)\n",
    "VALUES \n",
    "    ('TURBINE_00000', (turbine_lookup output), 85.50, 'Schedule immediate inspection', 3, \n",
    "     'HIGH URGENCY: Multiple sensor anomalies detected', 'Ticket not filed due to low maintenance alerts', '<Ticket ID>, null if does not exist', False, 'Need to File');\n",
    "</Example Query>\n",
    "     \n",
    "    For turbine_details_and_status, grab the latest information about a turbine using turbine_lookup.\n",
    "     \n",
    "    For Turbines that do not require any action, do a simple update saying no ticket filed.\"\"\"\n",
    "\n",
    "  query: str = dspy.InputField()\n",
    "  turbine_ticket_status: list[dict] = dspy.OutputField(desc=\"\"\"each turbine should have it's own entry like this: {\"turbine\": \"TURBINE_00000\", \"ticket_status\": \"Need to File\"}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16463d4f-a3ee-49a6-b16c-9e1e498565f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'turbine': 'TURBINE_00000', 'ticket_status': 'Need to File'}, {'turbine': 'TURBINE_00001', 'ticket_status': 'Need to File'}, {'turbine': 'TURBINE_00005', 'ticket_status': 'Need to File'}, {'turbine': 'TURBINE_00007', 'ticket_status': 'Need to File'}]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-c7c0b03bf106850ac75ff88b1a1d92d8\"",
      "text/plain": [
       "Trace(trace_id=tr-c7c0b03bf106850ac75ff88b1a1d92d8)"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "predictor = dspy.ReAct(query_dispatch_decider, tools=[agent_status_update, turbine_lookup])\n",
    "result = predictor(query=query_results)\n",
    "print(result.turbine_ticket_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80dc14b5-f478-48b9-ade5-fdb9d38bf700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### File Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22cc5d25-ac76-4fc6-b91f-0144c9406766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ticket_status_lookup(query):\n",
    "  \"\"\"Queries must be in postgres syntax. The column ticket_status will contain the status. The table is turbine_monitoring with this schema: \n",
    "  turbine_monitoring (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                turbine_id VARCHAR(50) NOT NULL,\n",
    "                turbine_details_and_status TEXT,\n",
    "                dispatch_priority_score DECIMAL(5,2),\n",
    "                recommended_action TEXT,\n",
    "                maintenance_alerts_count INTEGER DEFAULT 0,\n",
    "                agent_summary TEXT,\n",
    "                last_agent_action_taken TEXT,\n",
    "                Ticket_ID VARCHAR(50),\n",
    "                ticket_filed BOOLEAN DEFAULT FALSE,\n",
    "                ticket_status VARCHAR(50),\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\"\"\"\n",
    "  with psycopg2.connect(\n",
    "      host=instance.read_write_dns,\n",
    "      dbname=\"databricks_postgres\",\n",
    "      user=f\"{current_username}\",\n",
    "      password=cred.token,\n",
    "      sslmode=\"require\"\n",
    "  ) as conn:\n",
    "      with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchall() \n",
    "  return result\n",
    "\n",
    "def file_a_ticket(query):\n",
    "  \"\"\"Queries must be in postgres syntax. The column ticket_status will contain the status. The Table is ticket_mock_table with this schema:\n",
    "  ticket_mock_table (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                Ticket_ID VARCHAR(50) NOT NULL,\n",
    "                turbine_id VARCHAR(50) NOT NULL,\n",
    "                ticket_status_output Text,\n",
    "                Ticket_Submission Text,\n",
    "                Ticket_Status Text,\n",
    "                Last_Update TIMESTAMP,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\"\"\"\n",
    "  with psycopg2.connect(\n",
    "      host=instance.read_write_dns,\n",
    "      dbname=\"databricks_postgres\",\n",
    "      user=f\"{current_username}\",\n",
    "      password=cred.token,\n",
    "      sslmode=\"require\"\n",
    "  ) as conn:\n",
    "      with conn.cursor() as cur:\n",
    "          result = cur.execute(query)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ccab4c1-6e95-491e-9a99-6ec82c626a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class turbine_ticket_management(dspy.Signature):\n",
    "  \"\"\"Follow these Steps:\n",
    "  1. Use ticket_status_lookup to see if a ticket needs to be filed. Only use the latest entry for a Turbine. Pull all columns of turbines that 'Need to File'. Ticket_status must say 'Need to File. \n",
    "  2. Use file_a_ticket to file said ticket based on the information from ticket_status_lookup. Ticket_submission must be populated with turbine_details_and_status \n",
    "  3. Once a ticket is filed, Update the turbine entry from ticket_status_lookup to say \"Open\" instead of \"Need to File\", update last_agent_action_taken with 'filed a ticket' and update the ticket ID with the newly created Ticket ID \"\"\"\n",
    "  turbine: list = dspy.InputField() \n",
    "  response_of_completed_actions: str = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57725984-402f-428c-8c43-e4a1e6e86904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tickets successfully filed and turbine records updated:\n\n- TURBINE_00005 â†’ Ticket ID: TICKET_00005 (status Open, action filed a ticket)  \n- TURBINE_00007 â†’ Ticket ID: TICKET_00007 (status Open, action filed a ticket)  \n- TURBINE_00000 â†’ Ticket ID: TICKET_00000 (status Open, action filed a ticket)  \n- TURBINE_00001 â†’ Ticket ID: TICKET_00001 (status Open, action filed a ticket)\n\nAll turbine entries now show `ticket_status = 'Open'`, `last_agent_action_taken = 'filed a ticket'`, and the appropriate `Ticket_ID`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-fc0ad11b7a2fb5d84f97bf5d6e223302\"",
      "text/plain": [
       "Trace(trace_id=tr-fc0ad11b7a2fb5d84f97bf5d6e223302)"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "ticket_lookup = dspy.ReAct(turbine_ticket_management, tools=[ticket_status_lookup, file_a_ticket])\n",
    "ticket_status_output = ticket_lookup(turbine=result.turbine_ticket_status)\n",
    "print(ticket_status_output.response_of_completed_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a90387f-8612-4ca3-8888-201685c29ff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_65bc13ea-276c-4905-a728-9fe2fb1780e2",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8321753609643784,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "(Clone) Agent interaction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
